{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b45211-7188-422e-beac-c50f0d0e1862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 428 images belonging to 5 classes.\n",
      "Found 38 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "14/14 [==============================] - 22s 1s/step - loss: 10.2126 - accuracy: 0.4977 - val_loss: 5.5543 - val_accuracy: 0.5789\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.6160 - accuracy: 0.8598 - val_loss: 4.4764 - val_accuracy: 0.5526\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.6828 - accuracy: 0.9206 - val_loss: 1.5012 - val_accuracy: 0.7105\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.3173 - accuracy: 0.9509 - val_loss: 0.7734 - val_accuracy: 0.8158\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1947 - accuracy: 0.9673 - val_loss: 0.6979 - val_accuracy: 0.8421\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1672 - accuracy: 0.9743 - val_loss: 0.5854 - val_accuracy: 0.8421\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1429 - accuracy: 0.9790 - val_loss: 0.6436 - val_accuracy: 0.8947\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0767 - accuracy: 0.9860 - val_loss: 0.0786 - val_accuracy: 0.9737\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0578 - accuracy: 0.9883 - val_loss: 0.3741 - val_accuracy: 0.9474\n",
      "Epoch 10/15\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0849 - accuracy: 0.9860 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0397 - accuracy: 0.9930 - val_loss: 0.2286 - val_accuracy: 0.9211\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0261 - accuracy: 0.9930 - val_loss: 0.2314 - val_accuracy: 0.8947\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1018 - accuracy: 0.9790 - val_loss: 0.0284 - val_accuracy: 0.9737\n",
      "Epoch 14/15\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0617 - val_accuracy: 0.9737\n",
      "Epoch 15/15\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.0221 - accuracy: 0.9977 - val_loss: 6.0168e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\envs\\GG_1667\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "width, height = 224, 224 \n",
    "train_images = []\n",
    "train_path = \"C:/Users/hp/train\"\n",
    "\n",
    "# List all image files in the train_path directory\n",
    "train_files = [os.path.join(train_path, file) for file in os.listdir(train_path) if file.endswith('.jpeg')]\n",
    "\n",
    "for path in train_files:\n",
    "    img = cv2.imread(path)\n",
    "    if img is not None:\n",
    "        img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "        train_images.append(cv2.resize(img, (width, height)))\n",
    "    else:\n",
    "        print(f\"Warning: Image not found or could not be read at path: {path}\")\n",
    "\n",
    "test_images = []\n",
    "test_path = 'C:/Users/hp/test'\n",
    "\n",
    "# List all image files in the test_path directory\n",
    "test_files = [os.path.join(test_path, file) for file in os.listdir(test_path) if file.endswith('.jpeg')]\n",
    "\n",
    "for path in test_files:\n",
    "    img = cv2.imread(path)\n",
    "    if img is not None:\n",
    "        img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "        test_images.append(cv2.resize(img, (width, height)))\n",
    "    else:\n",
    "        print(f\"Warning: Image not found or could not be read at path: {path}\")\n",
    "\n",
    "\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "inception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "folders = glob('C:/Users/hp/train/*')\n",
    "\n",
    "x = Flatten()(inception.output)\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax', input_dim=10)(x)\n",
    "\n",
    "# create a model object\n",
    "\n",
    "model = keras.Model(inputs=inception.input, outputs=prediction)\n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/hp/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 classes=['Combat', 'Humanitarian Aid and rehabilitation', 'Military vehicles and weapons', 'Fire', 'DestroyedBuildings'])\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/hp/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            classes= ['Combat', 'Humanitarian Aid and rehabilitation', 'Military vehicles and weapons', 'Fire', 'DestroyedBuildings'])\n",
    "\n",
    "\n",
    "try:\n",
    "    r = model.fit(\n",
    "      training_set,\n",
    "      validation_data=test_set,\n",
    "      epochs=15,\n",
    "      steps_per_epoch=len(training_set),\n",
    "      validation_steps=len(test_set)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n",
    "    \n",
    "\n",
    "model.save('object_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154ca71-f098-4d63-ad43-d69696a08703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_1667",
   "language": "python",
   "name": "gg_1667"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
